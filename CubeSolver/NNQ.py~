import random
import sys
from keras.models import Sequential
from keras.layers import Dense, Activation
from keras.optimizers import SGD
import numpy as np

class ProgressBar:
	def __init__(self,width):
		self.width = width
		self.set(0.)
	def show(self):
		sys.stdout.write('\r[%s%s] %d %%'%('-'*int(self.p*self.width),' '*(self.width-int(self.width*self.p)),100*self.p))
		sys.stdout.flush()
		if (self.p>=1):
		    sys.stdout.write('\n')
		    sys.stdout.flush()
	def set(self,p):
		self.p = p

class Cube:
    def __init__(self):
        self.reset()
    def reset(self):
        self.facelets = []
        self.faces = {}
        [self.facelets.append(['g','b','o','r','w','y'][i/4]) for i in range(0,24)]
        self.faces['F'] = {'in':[0,1,2,3],'out':[19,18,12,15,21,20,10,9]}
        self.faces['B'] = {'in':[4,5,6,7],'out':[17,16,8,11,23,22,14,13]}
        self.faces['L'] = {'in':[8,9,10,11],'out':[16,19,0,3,20,23,6,5]}
        self.faces['R'] = {'in':[12,13,14,15],'out':[18,17,4,7,22,21,2,1]}
        self.faces['U'] = {'in':[16,17,18,19],'out':[5,4,13,12,1,0,9,8]}
        self.faces['D'] = {'in':[20,21,22,23],'out':[3,2,15,14,7,6,11,10]}
    def info(self):
        for i in range(0,24):
            if i % 4 == 0:
                print ['F','B','L','R','U','D'][i/4], ': ',
            print self.facelets[i],
            if i % 4 == 3:
                print ''
    def _lr(self,x,n,d): # d==1 clockwise
        return x[-n:]+x[:-n] if d==1 else x[n:]+x[:n]
    def _fr(self,face,d):
        for k,v in {'in': 1, 'out': 2}.iteritems():
            tmp = []
            indices = self.faces[face.upper()][k]
            [tmp.append(self.facelets[i]) for i in indices]
            tmp = self._lr(tmp, v, d)
            for i in indices:
                self.facelets[i] = tmp.pop(0)
        return self
    def rotate(self,face,d):
        return self._fr(face,d)
    def do(self,s):
        [self.rotate(f,f.isupper()) for f in s]
        return self
    def eq(self,cube):
        return True if self.facelets == cube.facelets else False
    def good(self):
        for i in range(0,24):
            if self.facelets[i] != self.facelets[i-i%4]: return False
        return True

class Qmodel:
    def __init__(self):
        self.model = Sequential()
        self.model.add(Dense(xx, activation='relu', input_dim=144))
        self.model.add(Dense(xx, activation='relu'))
        self.model.add(Dense(12, activation='relu'))



class Agent:
    actions = ['F','B','L','R','U','D','f','b','l','r','u','d']
    def __init__(self,tmax,alpha,gamma,exp): # TODO, time dependent alpha, gamma and exp
        self.tmax = tmax
        self.alpha = alpha
        self.gamma = gamma
        self.exp = exp
        self.qtable = {}
        self.cube = Cube()
        self.trainData = []
        self.testData = []
    def qinfo(self):
        nzCount = 0
        for s in self.qtable:
            for a in self.qtable[s]:
                if self.qtable[s][a] != 0:
                    nzCount = nzCount + 1
                    break
        print 'state space coverage: %d/%d, %.2f%%' % (nzCount, len(self.qtable), 100.0*nzCount/len(self.qtable))
    def reverseLast(self,act):
        return act[-1].upper() if act[-1].islower() else act[-1].lower()
    def clearTrainData(self):
        self.trainData = []
    def generateTrainData(self,maxMoves,trainSize):
        for n in range(1,maxMoves):
            for i in range(0,trainSize):
                self.trainData.append(''.join([random.choice(self.actions) for x in range(0,n)]))
    def clearTestData(self):
        self.testData = []
    def generateTestData(self,maxMoves,testSize):
        for n in range(1,maxMoves):
            for i in range(0,testSize):
                self.testData.append(''.join([random.choice(self.actions) for x in range(0,n)]))
    def do(self,act):
        self.cube.reset()
        self.cube.do(act)
    def getState(self, act):
        self.do(act)
        return ''.join(self.cube.facelets)
    def checkState(self,state):
        if state not in self.qtable:
            self.qtable[state] = {}
            for a in self.actions:
                self.qtable[state][a] = 0
    def reward(self,act,action): # TODO, time dependent reward
        self.do(act+action)
        return 100 if self.cube.good() else 0
    def train(self,maxMoves,trainSize):
        self.clearTrainData()
        self.generateTrainData(maxMoves,trainSize)
        print 'Training...'
        bar = ProgressBar(40)
        for i in range(0,len(self.trainData)):
            if 1.0*i/len(self.trainData) > bar.p:
                bar.set(bar.p+0.01)
                bar.show()
            act = self.trainData[i]
            for t in range(0,self.tmax):
                s = self.getState(act)
                self.checkState(s)
                prob = random.uniform(0,1)
                if prob <= self.exp:
                    action = random.choice(self.actions)
                else:
                    action = max(self.qtable[s],key=self.qtable[s].get)
                    #action = self.reverseLast(act) # a hint for the agent
                reward = self.reward(act,action)
                ns = self.getState(act+action)
                self.checkState(ns)
                self.qtable[s][action] = (1-self.alpha)*self.qtable[s][action]+\
                                         self.alpha*(reward+self.gamma*self.qtable[ns][max(self.qtable[ns],key=self.qtable[ns].get)])
                act = act + action
        self.qinfo()
    def solve(self,s,testTries):
        moves = s
        for t in range(0,testTries):
            state = self.getState(moves)
            if self.cube.good():
                return {'solved':True, 'permutation':s, 'moves':moves[len(s):]}
            if state not in self.qtable:
                action = random.choice(self.actions)
            else:
                action = max(self.qtable[state],key=self.qtable[state].get)
            moves = moves + action
        return {'solved':False, 'permutation':s, 'moves':moves[len(s):]}
    def singleTest(self,s,testTries):
        result = self.solve(s,testTries)
        print result
    def test(self,maxMoves,testSize,testTries):
        testCounts = {}
        recoveryCounts = {}
        solveLengths = {}
        for i in range(1,maxMoves):
            testCounts[i] = 0
            recoveryCounts[i] = 0
            solveLengths[i] = 0
        self.clearTestData()
        self.generateTestData(maxMoves,testSize)
        print 'Testing...'
        bar = ProgressBar(40)
        for i in range(0,len(self.testData)):
            if 1.0*i/len(self.testData) > bar.p:
                bar.set(bar.p+0.01)
                bar.show()
            a = self.testData[i]
            testCounts[len(a)] = testCounts[len(a)] + 1
            result = self.solve(a,testTries)
            if result['solved']:
                recoveryCounts[len(a)] = recoveryCounts[len(a)] + 1
            solveLengths[len(a)] = solveLengths[len(a)] + len(result['moves'])
        print 'recovery rates:'
        for i in range(1,maxMoves):
            print '%d\t %d%%\t %.2f' % (i, 100.0*recoveryCounts[i]/testCounts[i], 1.0*solveLengths[i]/testCounts[i])
            
agent = Agent(5,0.5,0.5,0.5)
for i in range(0,1000):
    print 'Train-Test Round: %d\n%s' % (i,'*'*100)
    agent.train(21,1000)
    agent.test(21,100,20)
    print '\n'






